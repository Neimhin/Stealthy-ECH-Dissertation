\chapter{Technical Background}
\section{Cryptographic Hash Functions}
A hash function is a function that maps arbitrary length data to a fixed length representation. An example of a (completely useless) hash function is the function that maps all inputs to the 0x00 byte. Useful hash functions often approximate a uniform distribution over the possible outputs for different inputs. If a hash function has an output length of one byte (256 possible outputs), and we feed in random strings to the hash function, it is desirable (for many use cases) if each of the 256 possibilities are approximately equally represented in the outputs. Hash functions with this property are useful in designing efficient algorithms and data structures (e.g. hash tables). However, the uniform distribution of outputs is not a sufficient property for making the hash function a secure cryptographic hash function. It is possible that the output of such a hash function reveals some information about the input. Let's construct an example of a hash function whose output reveals information about the input, we interpret the input message as an unsigned integer (with an arbitrary number of bits) and take the modulo of this integer and the number of possible outputs. Therefore the messages "0x00", "0x01", "0x02", ..., "0xFF" are all mapped to themselves, so we get a perfect uniform distribution for all one-byte messages. In fact, any message is just mapped to the least significant byte of the message, and therefore, the hash output tells us deterministically what the last byte of the message was. For hash functions used in cryptographic algorithms this is not acceptable; we need hash function where the hash digest (output) reveals nothing about the input message. Our insecure last-byte hash function is fast to compute (it's O(1), just take the last byte), but it turns out that cryptographically secure hash algorithms are more compute intensive because they ought to digest the entire input message (they are at least O(N)). One might not want to use a cryptographic hash function for non-cryptographic tasks (efficient lookup, hash tables etc.) because they may be more compute-intensive than non-cryptographic alternatives.
\section{AEAD}

[ ] AEAD in a nutshell

[ ] summary, how many available AEAD algorithms, exclusively use AEAD in TLS 1.3

[ ] description of the AEAD interface, requirements (unique nonce) and gaurantees over the values

[ ] Coordinating various devices using the same key requires some cleverness in nonce generation.

[ ] Using the same (nonce, key) pair results in the same key stream which is a "cryptographic disaster" (to quote RFC 7714 Section 6). See explanation in Section 9.1 of RFC3711.

\section{HKDF}

[ ] The HMAC-based Extract-and-Expand Key Derivation Functions (HKDF) described in RFC 5869 are used ubiquitously in the TLS 1.3 protocol for the derivation of various traffic encrpytion keys from the master secret derived in the handshake. Additionally the HKDF is proposed to be used for the ECH `accept_confirmation` 8 bytes acceptance signal (see e.g. Section 7.2 of [TODO cite tls-esni-draft-18]). A Hashed Message Authentication Code (HMAC) (described in [TODO cite RFC 2104]) is a pattern for performing message authentication based on cryptographic hash functions, and the authentication is secured with a secret key. The pattern works with any iterative cryptographic hash function. A HMAC scheme enables the calculation of the HMAC over data with a secret a key, and verification that the HMAC matches the data and secret key. A successful verificatoin of the HMAC implies that the data have not been tampered with (with high probability), and that the HMAC was calculated by someone who knows the secret key (with high probability). The precise security properties of the HMAC depends on the underlying cryptographic hash function.

[ ] The HKDF scheme is all about transforming some intput keying material (IKM) (some source of secret randomness/entropy) into a set of (yes multiple!) pseudorandom cryptographic keys. If the input keying material is already cryptographically strong and of the appropriate length then the HKDF-extract stage can be safely skipped and the IKM directly into a sequence of pseudorandom keys using the HKDF-expand function. It is possible, however, that the input keying material may be too long to be directly used in the HKDF-expand function, or it may not be cryptographically suitable, e.g. the Diffie-Hellman value $g^{xy}$ is not uniformly random and therefore not suitable as a PRK for the HKDF-Expand step. So long as the input keying material contains sufficient entropy (read randomness), we can extract an appropriately long, uniformly (pseudo)random key from the input keying material by applying the HKDF-extract function. For simplicity, when protocols use the extract-then-expand pattern, one can decide to always apply the HKDF-Extract stage, even if it is not always cryptographically necessary.

[ ] The HKDF-Extract function (the first step in the HKDF pattern) takes as input a salt (a non-secret random value) and the IKM to produce a pseudo-random key (PRK). The salt is optional and is set to all zeros if not provided to the function, but is highly recommended in RFC 5869 Section 3.1. Ideally the salt should be a random string with length equal to the length of the output of the underlying hash function used. The second step is the HKDF-Expand  function which takes as input a pseudorandom key, an optional information string (termed the label in TLS 1.3), and the desired length of the output, to produce the output keying material (OKM). The HKDF-Extract function is implemented as `HKDF-Extract(salt, IKM) = HMAC-Hash(salt, IKM)`, where the salt is being used as the key for the HMAC-Hash (but it does not have to be secret) and the IKM is the input message of the HMAC-Hash function. This means that the IKM can have arbitrary length. The OKM is generated recursively as `T(n) = HMAC-Hash(PRK, concatenate(T(n-1), info, n))`, but where `T(0)` is an empty string. This recursive pattern means that the OKM can be arbitrarily long. The info parameter in HKDF-Expand can be used to bind the OKM to particular contexts, e.g. in TLS 1.3 client-to-server and server-to-client encryption keys are generated with different info parameters. 

\section{TLS 1.3}
\subsection{HRR}
With TLS 1.3 the server can generate the application traffic key after processing just one flight of messages from the client. This is possible because the client 'guesses' a cipher suite and sends an appropriate `key_share` in the ClientHello (in fact the client may send multiple `key_share`s for multiple cipher suites to increase the probability that the server will support at least one of those cipher suites. However, if the client guesses wrong and sends a `key_share` for a cipher suite not supported by the server, then the server should respond with a message that informs the client as to which cipher suites are supported. This subsequent message is called the HelloRetryRequest (HRR); 'Hello' because it is the first message sent by the server (if it is sent), and 'RetryRequest' because the server is asking the client to send a new ClientHello message (CH2) using a different cipher suite. The HRR message format is designed to look almost identical to the ServerHello (SH) message for compatibility with hardened TLS 1.2 middleboxes that fail to correctly ignore new message types (TODO: review this sentence). From the perspective of a middlebox that is unaware of TLS 1.3 the HRR is treated just like a SH, but the client can distinguish between HRR and SH based on a special value in the `random` field of the message (which we would call the `ServerHello.random` if we interpreted the HRR as a SH).

The use of the special constant value in `random` field of the HRR has implications for the design of the ECH protocol. In the 'normal' case when the server supports the cipher suites used in the first `ClientHello`, and when the server also accepts ECH, then the last 8 octets of the `ServerHello.random` are filled with a special ECH acceptance signal. But in the case where HRR is necessary and ECH is accepted the last 8 octets of the `HRR.random` are not available because they are used to distinguish that the message is a HelloRetryRequest. Instead, in the case of HRR and ECH acceptance the ECH 8 byte acceptance signal is put in the `payload` field of an "encrypted_client_hello" extension (as described in Section 7.2.1 of RFC [TODO cite tls-esni-18]).

[ ] HRR Hijacking Explained

[ ] Risk of attacker using server as an oracle to reveal the inner SNI by forging a CH2.
        - For a design of a stealthy ECH protocol we require that the SECH acceptance signal also be stealthy. For ECH the acceptance signal is stealthy in the case that HRR is skipped, but it is not stealthy when HRR occurs. To facilate HRR while performing SECH we need a new mechanism to sneak the SECH acceptance signal to the client. One approach would be to delay the SECH acceptance signal until the true ServerHello, and put the SECH acceptance signal `ServerHello.random`. Another approach would be to use any other available random bytes in a typical HRR and replace them with the acceptance signal.

\subsection{Tickets and Session Resumption}

[ ] A TLS 1.3 server can issue tickets to clients after successful completion of a handshake. These tickets allow a client to initiate new TLS 1.3 sessions with the client in fewer steps (and with less computation) than is needed in the initial handshake.

[ ] The motivation for the TLS 1.3 ticket system comes from the typical behaviour of web browsers when loading and rendering web pages. Many contemporary web pages rely on a large number of resources to be loaded from the server. With the TLS ticketing system it is typical for a HTTPS server to issue several tickets (e.g. 6 or more) for every successful handshake. This means that when a web browser is loading a web page it can first complete a full handshake, and then open several more TLS connections to the server concurrently in order to load subsequent resources more quickly (e.g. images, videos, JavaScript files).

[ ] Details of tickets as specified by TLS 1.3 RFC. psk_binder, NewSessionTicket message type, what happens when multiple servers have authority on the server's certificate?

[ ] Stateful/stateless cookies.

[ ] Notes about how tickets are typically used in reality. Notes about any strict restrictions on the ticket behaviour in TLS 1.3 RFC.

[ ] Introduce idea of using tickets to distribute access to an SECH server (will this be a way to distribute a symmetric key, or can the ticket allow a one-time connection that does not require the symmetric key?).
      - ECH

[ ] Distributing Access to Backend Servers: (for TLS 1.3 the client just needs the servername and IP address, but for ECH the client additionally needs the public key of the ECH backend server). The ECHConfig will typically be distributed using DNS, which means that the ECH backend server will be advertising its own existence to users and censors alike. But other ways of distributing ECH configurations (which a client needs to establish a connection to a backend ECH server), such as having the ECH config preconfigured in the client, are also permissable.

[ ] Considering that the ECH protocol is not stealthy there is little harm done in advertising the existence of the ECH backend server, it would be possible for a powerful attacker to enumerate backend servers with high confidence using DPI and traffic analysis.

[ ] For SECH we have an opportunity to hide the existence of backend SECH servers from attackers, which may be particularly beneficial for censorship-circumvention use cases. If the existence of the backend SECH server can be hidden from potential censors then the censor will not be motivated to (over)block access to the SECH facilitating client-facing server. More on this later.

\section{Considering a stealthy variant of ECH}
\subsection{Offering Both ECH and SECH}
While it is not immediately obvious that offering **both** ECH and a stealthy SECH variant could be beneficial there are some circumstances where offering both may in the future be necessary to protect privacy or facilitate censorship circumvention. In particular the risk that ECH will be blocked outright by some powerful censors (e.g. in China), means that the convenience and enhanced privacy of regular ECH may be preferable in regions where ECH is not blocked, but the stealthy alternative may be the only way to access the domain privately from regions where ECH is blocked. This is a clear case where domains may in future wish to offer both ECH and SECH.

But offering thes two methods for accessing a resource privately is an inherent increase in complexity of the overall system compared to a system that only offers *either* ECH *or* SECH. This increase in complexity increases the attack surface of the system, there will be more branches of code on both the client and the server, the cost of developing and deploying the additional code will be significant, and the simultaneously co-operability of the two protocols presents new challenges to the design of each. That the two protocols should co-operate also introduces an additional burden of analysis in terms of identifying and mitigating attacks against each of the protocols. For all of these reasons there is a strong temptation to pursue developing versions of ECH and SECH that are designed *not* to co-operate with each other. However, another pattern of argument relevant to most security protocols emphasises the importance of having a stand-by backup option to a widely deployed algorithm. For instance, the most popular/widely-deployed AEAD algorithm on the internet is AES-128-GCM, but many software packages also support ChaCha20-Poly1305 because it could transpire at any moment that AES-128-GCM has a fundamental flaw and needs to be replaced urgently. This argument can also be applied to ECH and SECH; it would be wise to have both options ready, well-analysed, and deployed such that either one can be quickly disabled in case a fatal security flaw is discovered.

The above argument pertains to the simultaneous deployment of ECH and SECH for a single domain, but what about having versions of SECH and ECH that facilitate the server accepting both ECH and SECH within a single TLS session? Is there a motivation for such a design? Consider, for example, an enterprise network in which the enterprise has control of client devices and is able to manage the list of trusted CAs on each client device. In such a case the enterprise network administrator will be able to mount a MITM attack, which would allow inspection of the TLS 1.3 application traffic as well as the encrypted ClientHello if ECH is being used. There is motivation for network administrators to enforce such a situation for various reasons, e.g. the enterprise network may be attempting to thwart phishing campaigns, and the risks of phishing campaigns can be mitigated by blocking traffic to suspicious or known malevolent domain names. We can foresee a scenario, then, where the network administrator decides to mount a MITM attack in order to inspect the encrypted ClientHello, but no other part of the TLS 1.3 encrypted traffic. Let's imagine now we have a client trying to circumvent this MITM attack. If ECH is available and used by default then it would be suspicious for the client not to use ECH. However, the client may observe that using ECH to connect to `blocked.example.com` gets blocked, and therefore will have to access `blocked.example.com` by some other means. In such a case the client would benefit from the ability to make a 'cover' ECH connection request (to `allowed.example.com`, say) and simultaneously an SECH connection request to `blocked.example.com`. To accomodate this scenario we would like for it to be possible to attempt ECH and SECH on the same connection.

It seems unlikely, however, that there would be much benefit from the server being able to accept both ECH and SECH, since the acceptance signal for ECH is sent in the same flight as the server certificate. If ECH and SECH are both accepted by the server, but with differing inner servernames (e.g. `ech.example.com` and `sech.example.com`), the server will have to select a certificate to send for the same flight of messages as the ECH acceptance signal. Possibly, it would be beneficial to the client to know that both were accepted, such that it can decide how to try to establish subsequent connections. 

\subsection{Accepting SECH}

[ ]  The ECH acceptance signal is necessary because the client continues the handshake differently (e.g. the Finished message is constructed with a transcript using the ClientHelloInner) when it detects a positive ECH accept_confirmation signal from the server. The design of the ECH acceptance signal facilitates ECH split-mode, in which the backend server only processes one ClientHello (ClientHelloInner if the client-facing server accepts ECH, and ClientHelloOuter otherwise).

[ ] The purpose of an SECH acceptance signal is to inform the client as early as possible whether or not the server is intending to use the inner or outer servername. It is sufficient to include only a positive signal (the server is accepting the SECH inner servername), and to infer that the outer servername will be used when the positive signal is absent.
    - Detecting the length of the domain name

[ ] must not be possible for an attacker to detect the length of the inner servername, merely knowing the length of the servername could leak the servername itself
